{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"00 Course Introduction | Getting started with PySpark.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPOmc1JndqIAmrNDKXhwksv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Hhk01BduvNpD"},"source":["# Welcome to this course/playlist on \"Getting started with PySpark\" - Hands-on"]},{"cell_type":"markdown","metadata":{"id":"rzCdSTO3ugRE"},"source":["## Contents\n","- Course Introduction\n","- What is PySpark and Why should you learn PySpark?\n","- Contents of this course"]},{"cell_type":"markdown","metadata":{"id":"YFrGvwCZQySA"},"source":["## PySpark Introduction - Why should you learn PySpark?\n","\n","- Python + Apache Spark = PySpark\n","  - Python is one of the most popular languages for data preprocssing, wrangling and data modeling when it comes to Data Science and Machine Learning.\n","  - Apache Spark is the most powerful big data tool (a parallel distributed processing framework). The core power is to handle huge amounts of data. When you are working on a cluster, it can distribute the tasks/processing across nodes.\n","  - Spark is written in Scala and runs on the JVM (Java Virtual Machine). With PySpark, we can levearge the power of Apache Spark using Python.\n","\n","  ![PySpark](https://drive.google.com/uc?id=1iIMwsrq15ZD2-dm7gNBL2kHDD8YWWUxW)\n","\n","- PySpark is an interface for Apache Spark in Python. It not only allows you to write Spark applications using Python APIs, but also provides the PySpark shell for interactively analyzing your data in a distributed environment. \n","- Spark has built-in components for processing streaming data, machine learning (SparkML), graph processing (GraphX), and even interacting with data via SQL (Spark SQL).\n","- PySpark supports most of Sparkâ€™s features such as \n","  - Spark SQL and DataFrame (The sql function on a SparkSession enables applications to run SQL queries programmatically and returns the result as a DataFrame.)\n","  - Spark Streaming\n","  - MLlib (Machine Learning - Building models and creating pipelines) and \n","  - Spark Core (underlying general execution engine for the Spark platform that all other functionality is built on top of).\n","    <div>\n","    <img src=\"https://drive.google.com/uc?id=1aPClbi4lF5BKLH2YEPFavZBj_QzZG_M3\" width=\"500\"/>\n","    </div>\n","  - Reference: https://spark.apache.org/docs/latest/api/python/index.html\n","- Summary\n","  - If you know Python, then you can easily learn PySpark and leverage the power of Apache Spark."]},{"cell_type":"markdown","metadata":{"id":"y6ckgptKvV2W"},"source":["## Contents of this course\n","- In this course, I will cover basics of PySpark and if you are looking to start learning PySpark for your projects, then this course for you.\n","  ![PySpark](https://drive.google.com/uc?id=1oU2tHXn4Tb4NJ0GQLbFQanLUVWj-3M-G)\n","- This is the first video of this course and will be uploading videos regularly on YouTube to cover the basic concepts to get started with PySpark. This course is purely a hands-on course. Some of the topics that I will cover in this course are:\n","  - Setting up the environment on Colab\n","  - How Apache Spark works and it's components\n","  - Read and write data in PySpark\n","  - Convert Pyspark dataframe to pandas and vice versa\n","  - Summarizing data in PySpark (describe, percentiles, schema)\n","  - PySpark Transformations and Actions: Lazy execution\n","  - User defined functions in PySpark\n","  - Window functions in PySpark\n","  - Machine Learning using SparkML in PySpark\n","  - PySparkling Water: Leveraging H2O's Sparkling Water for modeling\n","  - End to end projects in PySpark\n","- In future, I will be adding update the playlist by making videos on new topics and add them to the course. There are a lot of things other than the above mentioned topics.\n","- NOTE: For the entire course, we are going to use Google Colab/Databricks for development."]},{"cell_type":"markdown","metadata":{"id":"6-ZhnANA7lFi"},"source":["### Thank you :)\n","-  That's the end of the first video of this course. I hope you liked the content of the course. Looking forward for your support in the coming videos. At the end of this course, you will be able to do projects in PySpark.\n","- If you like this video, please do like, share and subscribe to my channel.\n","<div>\n","<img src=\"https://drive.google.com/uc?id=1ttB2gJaw0cXuJfj6GBx5VaYf2ArjiRXM\" width=\"200\"/>\n","</div>"]},{"cell_type":"code","metadata":{"id":"1EQvVfA0c9ZO"},"source":[""],"execution_count":null,"outputs":[]}]}