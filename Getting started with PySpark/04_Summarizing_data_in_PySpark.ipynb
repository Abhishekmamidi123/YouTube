{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04 Summarizing data in PySpark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZdCWj0J-h37"
      },
      "source": [
        "## Welcome to this course \"Getting started with Apache Spark\"\n",
        "## Video: Summarize data in PySpark\n",
        "\n",
        "![PySpark](https://drive.google.com/uc?id=1oU2tHXn4Tb4NJ0GQLbFQanLUVWj-3M-G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxgd2dUX84JY"
      },
      "source": [
        "## Contents\n",
        "- Summarize dataframe in PySpark\n",
        "  - Shape (rows x no. of columns)\n",
        "  - Schema\n",
        "  - describe (min, max, count)\n",
        "  - percentiles (25%, 50%, 75%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZOGrY2mf5wK"
      },
      "source": [
        "## Setting up the PySpark environment\n",
        "- Check out this video for more details: https://www.youtube.com/watch?v=r5PbUuLUZiE\n",
        "  - You can check out the link in the description below\n",
        "- You can use the below cell to install all the required libraries and files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7C3o1Vqp5De",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53366f9f-15ae-439e-8236-b0bda948543f"
      },
      "source": [
        "# Setting up the PySpark environment\n",
        "\n",
        "# Install java 8\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download Apache Spark binary: This link can change based on the version. Update this link with the latest version before using\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz\n",
        "\n",
        "# Unzip file\n",
        "!tar -xf spark-3.0.2-bin-hadoop2.7.tgz\n",
        "\n",
        "# Install findspark: Adds Pyspark to sys.path at runtime\n",
        "!pip install -q findspark\n",
        "\n",
        "# Install pyspark\n",
        "!pip install pyspark\n",
        "\n",
        "# Add environmental variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.2-bin-hadoop2.7\"\n",
        "\n",
        "# findspark will locate spark in the system\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Waiting for headers] [Co\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [2 InRelease 14.2 kB/88.7\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (102 kB/s)\n",
            "Reading package lists... Done\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tdA-RWoozaM"
      },
      "source": [
        "### Initialize SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VecXeDgQRfgw"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "        .master(\"local\") \\\n",
        "        .appName(\"Hands-on PySpark on Google Colab\") \\\n",
        "        .getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyNSC9w52GXz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "30eeebf6-a1da-41ec-ce58-1c723ca4f3eb"
      },
      "source": [
        "spark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://f11f41ff9f53:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Hands-on PySpark on Google Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f628bf7a950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRxP4ge6Vsw_"
      },
      "source": [
        "## Summarize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkxPdO75nLrH"
      },
      "source": [
        "### Read data\n",
        "Dataset (In-vehicle coupon recommendation): https://archive.ics.uci.edu/ml/machine-learning-databases/00603/in-vehicle-coupon-recommendation.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLhz2C8EiP5o"
      },
      "source": [
        "!wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/00603/in-vehicle-coupon-recommendation.csv -P sample_data/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co-iMsc8V_H-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36bcd94f-0961-4767-927d-2531d26e8c80"
      },
      "source": [
        "# We can set header='true' and inferSchema='true' to infer the schema while reading the data\n",
        "\n",
        "filepath = \"sample_data/in-vehicle-coupon-recommendation.csv\"\n",
        "spark_df = spark.read.format('csv').options(header='true', inferSchema='true').load(filepath)\n",
        "spark_df.show(5, truncate=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+---------+-------+-----------+----+---------------------+----------+------+---+-----------------+------------+------------------------+----------+---------------+----+-----+-----------+---------+--------------------+----------------+----------------+-----------------+-----------------+--------------+-------------+---+\n",
            "|destination    |passanger|weather|temperature|time|coupon               |expiration|gender|age|maritalStatus    |has_children|education               |occupation|income         |car |Bar  |CoffeeHouse|CarryAway|RestaurantLessThan20|Restaurant20To50|toCoupon_GEQ5min|toCoupon_GEQ15min|toCoupon_GEQ25min|direction_same|direction_opp|Y  |\n",
            "+---------------+---------+-------+-----------+----+---------------------+----------+------+---+-----------------+------------+------------------------+----------+---------------+----+-----+-----------+---------+--------------------+----------------+----------------+-----------------+-----------------+--------------+-------------+---+\n",
            "|No Urgent Place|Alone    |Sunny  |55         |2PM |Restaurant(<20)      |1d        |Female|21 |Unmarried partner|1           |Some college - no degree|Unemployed|$37500 - $49999|null|never|never      |null     |4~8                 |1~3             |1               |0                |0                |0             |1            |1  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |10AM|Coffee House         |2h        |Female|21 |Unmarried partner|1           |Some college - no degree|Unemployed|$37500 - $49999|null|never|never      |null     |4~8                 |1~3             |1               |0                |0                |0             |1            |0  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |10AM|Carry out & Take away|2h        |Female|21 |Unmarried partner|1           |Some college - no degree|Unemployed|$37500 - $49999|null|never|never      |null     |4~8                 |1~3             |1               |1                |0                |0             |1            |1  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |2PM |Coffee House         |2h        |Female|21 |Unmarried partner|1           |Some college - no degree|Unemployed|$37500 - $49999|null|never|never      |null     |4~8                 |1~3             |1               |1                |0                |0             |1            |0  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |2PM |Coffee House         |1d        |Female|21 |Unmarried partner|1           |Some college - no degree|Unemployed|$37500 - $49999|null|never|never      |null     |4~8                 |1~3             |1               |1                |0                |0             |1            |0  |\n",
            "+---------------+---------+-------+-----------+----+---------------------+----------+------+---+-----------------+------------+------------------------+----------+---------------+----+-----+-----------+---------+--------------------+----------------+----------------+-----------------+-----------------+--------------+-------------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NuaK3xx9KSv",
        "outputId": "c81b40cb-47fd-409f-9876-2495fec89d85"
      },
      "source": [
        "columns_to_use = [\"destination\", \"passanger\", \"weather\", \"temperature\", \"time\", \"coupon\", \"gender\", \"age\", \"has_children\", \"toCoupon_GEQ5min\", \"Y\"]\n",
        "spark_df = spark_df.select(*columns_to_use)\n",
        "spark_df.show(5, truncate=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+---------+-------+-----------+----+---------------------+------+---+------------+----------------+---+\n",
            "|destination    |passanger|weather|temperature|time|coupon               |gender|age|has_children|toCoupon_GEQ5min|Y  |\n",
            "+---------------+---------+-------+-----------+----+---------------------+------+---+------------+----------------+---+\n",
            "|No Urgent Place|Alone    |Sunny  |55         |2PM |Restaurant(<20)      |Female|21 |1           |1               |1  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |10AM|Coffee House         |Female|21 |1           |1               |0  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |10AM|Carry out & Take away|Female|21 |1           |1               |1  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |2PM |Coffee House         |Female|21 |1           |1               |0  |\n",
            "|No Urgent Place|Friend(s)|Sunny  |80         |2PM |Coffee House         |Female|21 |1           |1               |0  |\n",
            "+---------------+---------+-------+-----------+----+---------------------+------+---+------------+----------------+---+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0G8ANLy9i6t"
      },
      "source": [
        "### Shape of the dataframe (count x number of columns)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYRK5CoZ6-aF",
        "outputId": "300410ee-f285-4481-95ff-d35ac339abf1"
      },
      "source": [
        "spark_df.count()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12684"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ycw4Fo_G9rPm",
        "outputId": "a4180cb7-af11-4c6f-d077-48958d376804"
      },
      "source": [
        "print(spark_df.columns)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['destination', 'passanger', 'weather', 'temperature', 'time', 'coupon', 'gender', 'age', 'has_children', 'toCoupon_GEQ5min', 'Y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1-z-9Bj9vyy",
        "outputId": "f3491c81-d565-4c6c-bc04-5dfef126e432"
      },
      "source": [
        "len(spark_df.columns)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaW2VTqN90nF"
      },
      "source": [
        "### Schema of the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUb6x4t39zcS",
        "outputId": "2b3b2ba6-4ff4-4b5c-b5f3-cc2539976870"
      },
      "source": [
        "spark_df.printSchema()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- destination: string (nullable = true)\n",
            " |-- passanger: string (nullable = true)\n",
            " |-- weather: string (nullable = true)\n",
            " |-- temperature: integer (nullable = true)\n",
            " |-- time: string (nullable = true)\n",
            " |-- coupon: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- has_children: integer (nullable = true)\n",
            " |-- toCoupon_GEQ5min: integer (nullable = true)\n",
            " |-- Y: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBtqELdQ-2PV",
        "outputId": "0e3b06d1-c9b7-477f-a2c2-c906ef218ace"
      },
      "source": [
        "spark_df.dtypes"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('destination', 'string'),\n",
              " ('passanger', 'string'),\n",
              " ('weather', 'string'),\n",
              " ('temperature', 'int'),\n",
              " ('time', 'string'),\n",
              " ('coupon', 'string'),\n",
              " ('gender', 'string'),\n",
              " ('age', 'string'),\n",
              " ('has_children', 'int'),\n",
              " ('toCoupon_GEQ5min', 'int'),\n",
              " ('Y', 'int')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2MAHGfe97uU"
      },
      "source": [
        "### Describe the dataframe (min, max, count)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzGaqv3397eN",
        "outputId": "05b9407b-aa1b-4aab-a403-25e3c32cd080"
      },
      "source": [
        "spark_df.describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, destination: string, passanger: string, weather: string, temperature: string, time: string, coupon: string, gender: string, age: string, has_children: string, toCoupon_GEQ5min: string, Y: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccuzydx8-IpN",
        "outputId": "7b5172a5-ed7d-4f3d-8daf-54a2ada0608e"
      },
      "source": [
        "# To get the output, you have to run action commands (like show, collect, etc.)\n",
        "spark_df.describe().show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+---------+-------+------------------+-----+---------------+------+------------------+------------------+----------------+------------------+\n",
            "|summary|destination|passanger|weather|       temperature| time|         coupon|gender|               age|      has_children|toCoupon_GEQ5min|                 Y|\n",
            "+-------+-----------+---------+-------+------------------+-----+---------------+------+------------------+------------------+----------------+------------------+\n",
            "|  count|      12684|    12684|  12684|             12684|12684|          12684| 12684|             12684|             12684|           12684|             12684|\n",
            "|   mean|       null|     null|   null|63.301797540208135| null|           null|  null|29.887815247850035|0.4141438032166509|             1.0|0.5684326710816777|\n",
            "| stddev|       null|     null|   null| 19.15448575684057| null|           null|  null| 7.697275065801651|   0.4925929797555|             0.0| 0.495314356461186|\n",
            "|    min|       Home|    Alone|  Rainy|                30| 10AM|            Bar|Female|                21|                 0|               1|                 0|\n",
            "|    max|       Work|  Partner|  Sunny|                80|  7AM|Restaurant(<20)|  Male|           below21|                 1|               1|                 1|\n",
            "+-------+-----------+---------+-------+------------------+-----+---------------+------+------------------+------------------+----------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHGqpV2M-4k2"
      },
      "source": [
        "### Percentiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIVBtYOk-Mmk",
        "outputId": "0a0c1966-7e96-46e0-d898-6fc22203b358"
      },
      "source": [
        "spark_df.summary().show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+---------+-------+------------------+-----+---------------+------+------------------+------------------+----------------+------------------+\n",
            "|summary|destination|passanger|weather|       temperature| time|         coupon|gender|               age|      has_children|toCoupon_GEQ5min|                 Y|\n",
            "+-------+-----------+---------+-------+------------------+-----+---------------+------+------------------+------------------+----------------+------------------+\n",
            "|  count|      12684|    12684|  12684|             12684|12684|          12684| 12684|             12684|             12684|           12684|             12684|\n",
            "|   mean|       null|     null|   null|63.301797540208135| null|           null|  null|29.887815247850035|0.4141438032166509|             1.0|0.5684326710816777|\n",
            "| stddev|       null|     null|   null| 19.15448575684057| null|           null|  null| 7.697275065801651|   0.4925929797555|             0.0| 0.495314356461186|\n",
            "|    min|       Home|    Alone|  Rainy|                30| 10AM|            Bar|Female|                21|                 0|               1|                 0|\n",
            "|    25%|       null|     null|   null|                55| null|           null|  null|              21.0|                 0|               1|                 0|\n",
            "|    50%|       null|     null|   null|                80| null|           null|  null|              26.0|                 0|               1|                 1|\n",
            "|    75%|       null|     null|   null|                80| null|           null|  null|              36.0|                 1|               1|                 1|\n",
            "|    max|       Work|  Partner|  Sunny|                80|  7AM|Restaurant(<20)|  Male|           below21|                 1|               1|                 1|\n",
            "+-------+-----------+---------+-------+------------------+-----+---------------+------+------------------+------------------+----------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74GUpTbO_BWr",
        "outputId": "95772c28-5840-4ba2-e254-1d4e50cbbe9c"
      },
      "source": [
        "spark_df.summary(\"40%\", \"60%\", \"90%\").show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+---------+-------+-----------+----+------+------+----+------------+----------------+---+\n",
            "|summary|destination|passanger|weather|temperature|time|coupon|gender| age|has_children|toCoupon_GEQ5min|  Y|\n",
            "+-------+-----------+---------+-------+-----------+----+------+------+----+------------+----------------+---+\n",
            "|    40%|       null|     null|   null|         55|null|  null|  null|26.0|           0|               1|  0|\n",
            "|    60%|       null|     null|   null|         80|null|  null|  null|31.0|           1|               1|  1|\n",
            "|    90%|       null|     null|   null|         80|null|  null|  null|41.0|           1|               1|  1|\n",
            "+-------+-----------+---------+-------+-----------+----+------+------+----+------------+----------------+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mjsfQBR_okG"
      },
      "source": [
        "### To get other functions, you can directly see in Google Colab (using spark_df.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AfMAF-j_BTS"
      },
      "source": [
        "spark_df."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4ck1DNB4HBL"
      },
      "source": [
        "## Summary\n",
        "- We have seen how to extract basic statistics from a DataFrame using PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgaK8JRu4xnV"
      },
      "source": [
        "### Thank you :)\n",
        "-  That's the end of the this video. If you like this video, please do like, share and subscribe to my channel.\n",
        "- If you are on LinkedIn, please tag me and share your thoughts on this video and the series \"Getting started with PySpark - Hands on\". This will motivate me to make more videos.\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?id=1ttB2gJaw0cXuJfj6GBx5VaYf2ArjiRXM\" width=\"200\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCEnrMOm4zO-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}